{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":791155,"sourceType":"datasetVersion","datasetId":413408},{"sourceId":1020806,"sourceType":"datasetVersion","datasetId":561588},{"sourceId":1405070,"sourceType":"datasetVersion","datasetId":821469},{"sourceId":5514073,"sourceType":"datasetVersion","datasetId":3180204}],"dockerImageVersionId":30085,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/swethaudayakumar3990/covid-19-classification-warriorz?scriptVersionId=224625071\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nimport os\nimport matplotlib.pyplot as plt\nimport torch.nn.functional as F \nfrom torch import nn,optim\nfrom torchvision import transforms as T,datasets,models\nfrom torchvision.utils import make_grid\nfrom torch.utils.data import DataLoader\nfrom collections import OrderedDict\nfrom tqdm import tqdm\npd.options.plotting.backend = \"plotly\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_dir = \"../input/covid19-chest-xray-detection/covid_update\"\nTEST = 'Test'\nTRAIN = 'Train'\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def data_transforms(phase = None):\n    \n    if phase == TRAIN:\n\n        data_T = T.Compose([\n            \n                T.Resize(size = (256,256)),\n                T.RandomRotation(degrees = (-20,+20)),\n                T.CenterCrop(size=224),\n                T.ToTensor(),\n                T.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n        ])\n    \n    elif phase == TEST or phase == VAL:\n\n        data_T = T.Compose([\n\n                T.Resize(size = (224,224)),\n                T.ToTensor(),\n                T.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n        ])\n        \n    return data_T","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainset = datasets.ImageFolder(os.path.join(data_dir, TRAIN),transform = data_transforms(TRAIN))\ntestset = datasets.ImageFolder(os.path.join(data_dir, TEST),transform = data_transforms(TEST))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class_names = trainset.classes\nprint(class_names)\nprint(trainset.class_to_idx)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def plot_class_count(classes,name = None):\n    pd.DataFrame(classes,columns = [name]).groupby([classes]).size().plot(kind = 'bar',title = name).show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def get_class_count(dataset,name = None):\n    classes = []\n    for _,label in dataset:\n        if label == 0:\n            classes.append(class_names[label])\n            \n        elif label == 1:\n            classes.append(class_names[label])\n            \n    return classes","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainset_class_count = get_class_count(trainset,name = 'trainset_classes_count')\nplot_class_count(trainset_class_count,name = 'trainset_classes_count')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"testset_class_count = get_class_count(testset,name = 'testset_classes_count')\nplot_class_count(testset_class_count,name = 'testset_classes_count')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainloader = DataLoader(trainset,batch_size = 16,shuffle = True)\ntestloader = DataLoader(testset,batch_size = 8,shuffle = True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def show_image(image,title = None,get_denormalize = False):\n    \n    image = image.permute(1,2,0)\n    mean = torch.FloatTensor([0.485, 0.456, 0.406])\n    std = torch.FloatTensor([0.229, 0.224, 0.225])\n    \n    image = image*std + mean\n    image = np.clip(image,0,1)\n    \n    if get_denormalize == False:\n        plt.figure(figsize=[15, 15])\n        plt.imshow(image)\n\n        if title != None:\n            plt.title(title)\n            \n    else : \n        return image","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataiter = iter(trainloader)\nimages,labels = dataiter.next()\n\nout = make_grid(images,nrow=4)\n\nshow_image(out, title=[class_names[x] for x in labels])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = models.vgg16()\nmodel.load_state_dict(torch.load(\"../input/pretrained-model-weights-pytorch/vgg16-397923af.pth\"))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for param in model.parameters():\n    param.requires_grad = False\n\n\n\n\nclassifier = nn.Sequential(OrderedDict([('fc1', nn.Linear(25088, 4096)),\n                                         ('relu', nn.ReLU()),\n                                         ('dropout',nn.Dropout(0.3)),\n                                         ('fc2', nn.Linear(4096, 4096)),\n                                         ('relu', nn.ReLU()),\n                                         ('drop', nn.Dropout(0.3)),\n                                         ('fc3', nn.Linear(4096, 2)), \n                                         ('output', nn.LogSoftmax(dim = 1))]))\n\nmodel.classifier = classifier\nmodel.to(device)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"criterion = nn.NLLLoss()\noptimizer = optim.Adam(model.parameters(),lr = 0.001)\nschedular = optim.lr_scheduler.ReduceLROnPlateau(optimizer,factor = 0.1,patience = 5)\nepochs = 5\nvalid_loss_min = np.Inf","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def accuracy(y_pred,y_true):\n    y_pred = torch.exp(y_pred)\n    top_p,top_class = y_pred.topk(1,dim = 1)\n    equals = top_class == y_true.view(*top_class.shape)\n    return torch.mean(equals.type(torch.FloatTensor))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for i in range(epochs):\n    \n    train_loss = 0.0\n    valid_loss = 0.0\n    train_acc = 0.0\n    valid_acc = 0.0 \n    \n    \n    model.train()\n    \n    for images,labels in tqdm(trainloader):\n        \n        images = images.to(device)\n        labels = labels.to(device)\n        \n        ps = model(images)\n        loss = criterion(ps,labels)\n        \n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        train_acc += accuracy(ps,labels)\n        train_loss += loss.item()\n        \n    avg_train_acc = train_acc / len(trainloader)\n    avg_train_loss = train_loss / len(trainloader)\n        \n    model.eval()\n    with torch.no_grad():\n        \n        for images,labels in tqdm(testloader):\n            \n            images = images.to(device)\n            labels = labels.to(device)\n            \n            ps = model(images)\n            loss = criterion(ps,labels)\n            \n            valid_acc += accuracy(ps,labels)\n            valid_loss += loss.item()\n            \n            \n        avg_valid_acc = valid_acc / len(testloader)\n        avg_valid_loss = valid_loss / len(testloader)\n        \n        schedular.step(avg_valid_loss)\n        \n        if avg_valid_loss <= valid_loss_min:\n            print('Validation loss decreased ({:.6f} --> {:.6f}).   Saving model ...'.format(valid_loss_min,avg_valid_loss))\n            torch.save({\n                'epoch' : i,\n                'model_state_dict' : model.state_dict(),\n                'optimizer_state_dict' : optimizer.state_dict(),\n                'valid_loss_min' : avg_valid_loss\n            },'Pneumonia_model.pt')\n            \n            valid_loss_min = avg_valid_loss\n            \n            \n    print(\"Epoch : {} Train Loss : {:.6f} Train Acc : {:.6f}\".format(i+1,avg_train_loss,avg_train_acc))\n    print(\"Epoch : {} Valid Loss : {:.6f} Valid Acc : {:.6f}\".format(i+1,avg_valid_loss,avg_valid_acc))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.eval() #evaluating the model\n\ntest_loss = 0\ntest_acc = 0\n\nfor images,labels in testloader:\n    \n    images = images.to(device)\n    labels = labels.to(device)\n    \n    pred = model(images)\n    loss = criterion(pred,labels)\n    \n    test_loss += loss.item()\n    test_acc += accuracy(pred,labels)\n    \navg_test_loss = test_loss/len(testloader)\navg_test_acc = test_acc/len(testloader)\n\nprint(\"Test Loss : {:.6f} Test Acc : {:.6f}\".format(avg_test_loss,avg_test_acc))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch.save({\n                'epoch' : i,\n                'model_state_dict' : model.state_dict(),\n                'optimizer_state_dict' : optimizer.state_dict(),\n                'valid_loss_min' : avg_valid_loss\n            },'covid-model.h5')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ndef view_classify(img,ps,label):\n    \n    class_name = ['NORMAL', 'COVID']\n    classes = np.array(class_name)\n\n    ps = ps.cpu().data.numpy().squeeze()\n    img = show_image(img,get_denormalize = True)\n    \n    \n\n    fig, (ax1, ax2) = plt.subplots(figsize=(8,12), ncols=2)\n    ax1.imshow(img)\n    ax1.set_title('Ground Truth : {}'.format(class_name[label]))\n    ax1.axis('off')\n    ax2.barh(classes, ps)\n    ax2.set_aspect(0.1)\n    ax2.set_yticks(classes)\n    ax2.set_yticklabels(classes)\n    ax2.set_title('Predicted Class')\n    ax2.set_xlim(0, 1.1)\n\n    plt.tight_layout()\n\n    return None","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**ACTUAL TESTING OF THE TRAINED MODEL **","metadata":{}},{"cell_type":"code","source":"image,label = testset[0]\n\nps = torch.exp(model(image.to(device).unsqueeze(0)))\nview_classify(image,ps,label) #function to classify the image","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"image,label = testset[135]\n\nps = torch.exp(model(image.to(device).unsqueeze(0)))\nview_classify(image,ps,label)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"image,label = testset[160]\n\nps = torch.exp(model(image.to(device).unsqueeze(0)))\nview_classify(image,ps,label)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"image,label = testset[35]\n\nps = torch.exp(model(image.to(device).unsqueeze(0)))\nview_classify(image,ps,label)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"image,label = testset[78]\n\nps = torch.exp(model(image.to(device).unsqueeze(0)))\nview_classify(image,ps,label)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"image,label = testset[180]\n\nps = torch.exp(model(image.to(device).unsqueeze(0)))\nview_classify(image,ps,label)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"image,label = testset[45]\n\nps = torch.exp(model(image.to(device).unsqueeze(0)))\nview_classify(image,ps,label)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"image,label = testset[45]\n\nps = torch.exp(model(image.to(device).unsqueeze(0)))\nview_classify(image,ps,label)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"image,label = testset[15]\n\nps = torch.exp(model(image.to(device).unsqueeze(0)))\nview_classify(image,ps,label)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"image,label = testset[40]\n\nps = torch.exp(model(image.to(device).unsqueeze(0)))\nview_classify(image,ps,label)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"image,label = testset[100]\n\nps = torch.exp(model(image.to(device).unsqueeze(0)))\nview_classify(image,ps,label)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"image,label = testset[80]\n\nps = torch.exp(model(image.to(device).unsqueeze(0)))\nview_classify(image,ps,label)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"image,label = testset[8]\n\nps = torch.exp(model(image.to(device).unsqueeze(0)))\nview_classify(image,ps,label)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"image,label = testset[31]\n\nps = torch.exp(model(image.to(device).unsqueeze(0)))\nview_classify(image,ps,label)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# in this case accuracy cannot be 100%. deviations may occur due to loss","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null}]}